#!/bin/bash

# Expected file structure (from .install):
#
# ../tmp/native_client/
#      *
# ../keep/
#      source_model/
#          checkpoint
#          model.meta
#          model.data
#          model.index
#
# Created by filter_train_dev_test.py (this script)
#
# ../keep/
#     target_lang/
#         valid_dev.csv
#         valid_test.csv
#         valid_train.csv
#
# Created by DeepSpeech.py (this script):
#
# ../keep/
#     target_lang/
#         source_model/
#             run/
#               RESULTS.json
#               summaries/
#               model/
#               ckpt/
#


source ../tmp/venv/bin/activate

# train from scratch with num_layers_dropped=6
target_lang='en'
source_model='en-v030'


input_dir="/snakepit/shared/data/mozilla/CommonVoice/v2.0-alpha2.0"
#input_dir="/home/josh/Downloads/CV"
data="../keep/${target_lang}"
mkdir $data


python3 filter_train_dev_test.py "${input_dir}" "${target_lang}" "${input_dir}/clips.tsv" "${data}"
python3 util/check_characters.py "${data}/*.csv"




###              ###
### FROM SCRATCH ###
###              ###


echo "##############################"
echo "STARTING TRAINING FROM SCRATCH"
echo "##############################"

exp="../keep/${target_lang}/scratch/"

python3 -u DeepSpeech.py \
	    --export_dir "${exp}/model/" \
	    --summary_dir "${exp}/summaries/" \
	    --checkpoint_dir "${exp}/ckpt/" \
	    --test_output_file "${exp}/RESULTS.json" \
	    --train_files "${data}/valid_train.csv"\
	    --dev_files "${data}/valid_dev.csv" \
	    --test_files "${data}/valid_test.csv" \
	    --n_hidden 2048 \
	    --epoch 1000 \
        --earlystop_nsteps 5 \
	    --train_batch_size 24 \
	    --dev_batch_size 48 \
	    --test_batch_size 48 \
	    --learning_rate 0.0001 \
	    --dropout_rate 0.2 \
	    --display_step 0 \
	    --validation_step 1 \
        --summary_secs 60 \
	    --decoder_library_path "../tmp/native_client/libctc_decoder_with_kenlm.so"



###                   ###
### TRANSFER LEARNING ###
###                   ###


# if [ $num_layers_dropped -lt 6 ]; then
for num_layers_dropped in 1 2 3 4 5; do

    echo "##########################"
    echo "STARTING TRANSFER LEARNING W/ FINE_TUNE"
    echo " num_layers_dropped=${num_layers_dropped}"
    echo "##########################"
    
    exp="../keep/${target_lang}/fine_tune/${num_layers_dropped}"

    python3 -u DeepSpeech.py \
            --fine_tune \
	        --export_dir "${exp}/model/" \
	        --summary_dir "${exp}/summaries/" \
	        --checkpoint_dir "${exp}/ckpt/" \
	        --test_output_file "${exp}/RESULTS.json" \
	        --drop_source_layers "${num_layers_dropped}" \
	        --source_model_checkpoint_dir "../keep/${source_model}" \
	        --train_files "${data}/valid_train.csv"\
	        --dev_files "${data}/valid_dev.csv" \
	        --test_files "${data}/valid_test.csv" \
	        --n_hidden 2048 \
	        --epoch -1000 \
            --earlystop_nsteps 5 \
	        --train_batch_size 24 \
	        --dev_batch_size 48 \
	        --test_batch_size 48 \
	        --learning_rate 0.0001 \
	        --dropout_rate 0.2 \
	        --display_step 0 \
	        --validation_step 1 \
            --summary_secs 60 \
	        --decoder_library_path "../tmp/native_client/libctc_decoder_with_kenlm.so"

    echo "##########################"
    echo "STARTING TRANSFER LEARNING W/ FROZEN"
    echo " num_layers_dropped=${num_layers_dropped}"
    echo "##########################"
    
    exp="../keep/${target_lang}/frozen/${num_layers_dropped}"

    python3 -u DeepSpeech.py \
	        --export_dir "${exp}/model/" \
	        --summary_dir "${exp}/summaries/" \
	        --checkpoint_dir "${exp}/ckpt/" \
	        --test_output_file "${exp}/RESULTS.json" \
	        --drop_source_layers "${num_layers_dropped}" \
	        --source_model_checkpoint_dir "../keep/${source_model}" \
	        --train_files "${data}/valid_train.csv"\
	        --dev_files "${data}/valid_dev.csv" \
	        --test_files "${data}/valid_test.csv" \
	        --n_hidden 2048 \
	        --epoch -1000 \
            --earlystop_nsteps 5 \
	        --train_batch_size 24 \
	        --dev_batch_size 48 \
	        --test_batch_size 48 \
	        --learning_rate 0.0001 \
	        --dropout_rate 0.2 \
	        --display_step 0 \
	        --validation_step 1 \
            --summary_secs 60 \
	        --decoder_library_path "../tmp/native_client/libctc_decoder_with_kenlm.so"
done





echo "$0: END"
